# Legal Case Retrieval and Summarization System

This repository contains a system for retrieving and summarizing legal cases using advanced NLP models. The system combines semantic search capabilities with abstractive summarization to help users find and understand relevant legal precedents.

---

## ğŸ§  Overview

The application implements two independent NLP approaches:

- **Case Retrieval using legal-xlm-RoBERTa**  
  A multilingual variant of RoBERTa fine-tuned on legal domain data. The model encodes legal documents and user queries into dense vector representations, enabling semantic search beyond simple keyword matching.

- **Abstractive Summarization using Legal-Pegasus**  
  A domain-adapted version of Pegasus designed specifically for summarizing legal texts. Legal-Pegasus generates concise, understandable summaries of lengthy legal documents.

Together, these models create a powerful tool that helps users discover relevant legal cases and quickly understand their content.

---

## ğŸ—‚ï¸ Repository Structure
```bash
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 0_web_scraping_cases.ipynb        # Web scraping legal cases
â”‚   â”œâ”€â”€ 1_convert_cases_pdf_to_txt.ipynb  # Converting PDFs to text
â”‚   â”œâ”€â”€ 2_main.ipynb                      # Core implementation and analysis, technically does the same thing as app.py but without the interface.
â”‚   â”œâ”€â”€ 3_case_embeddings_to_pickle.ipynb # Script to create and save embeddings
â”‚   â””â”€â”€ 4_testing.ipynb                   # run sample queries and save them into a simple format to enable lawyers to assess the performance
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ case_embeddings.pkl
â”‚   â”œâ”€â”€ extracted_texts.zip
â”‚   â””â”€â”€ test_results/
â”‚       â”œâ”€â”€ test_questions_cases_with_summaries.xlsx    
â”‚       â”œâ”€â”€ test_results_case_summaries.pkl
â”‚       â”œâ”€â”€ test_results_similar_cases.pkl
â”‚       â””â”€â”€ test_results_similar_cases.xlsx              # simple sheet  to enable lawyers to assess the performance
â”œâ”€â”€ README.md 
â”œâ”€â”€ app.py                                 # Main Streamlit application          
â””â”€â”€ requirements.txt                       # Python dependencies
```
---

## ğŸ› ï¸ Installation Instructions

### ğŸ“ Clone the repository

```bash
git clone https://github.com/yourusername/legal-case-retrieval.git
cd legal-case-retrieval
```

### ğŸ§ª Create a virtual environment and activate it

```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```
### ğŸ“¦ Install the required dependencies

```bash
pip install -r requirements.txt
```
---

## ğŸš€ Using the Application 
### â–¶ï¸ Start the Streamlit application

```bash
streamlit run app.py
```

- Open your browser and navigate to the URL displayed in the terminal (typically `http://localhost:8501`)
- Enter your legal query in the search box and hit **"Search Cases"**
- Review the retrieved cases and their summaries

---

### âœ¨ Key Features

- **Semantic Search**: Find cases based on meaning rather than just keywords  
- **Abstractive Summarization**: Get concise summaries of lengthy legal documents  
- **Interactive Interface**: Explore cases with an intuitive web interface  
- **Source Attribution**: All information is linked to source documents  

---
## ğŸ” Retrieval Model: `legal-xlm-RoBERTa`

- **Architecture**: Transformer-based encoder (RoBERTa variant)  
- **Training**: Fine-tuned on multilingual legal corpora  
- **Function**: Converts text into dense vector embeddings for semantic similarity search  
- **Advantage**: Can understand semantic relationships between legal concepts even when different terminology is used  

## âœ‚ï¸ Summarization Model: `Legal-Pegasus`

- **Architecture**: Encoder-decoder transformer with attention mechanisms  
- **Training**: Adapted from Pegasus with additional fine-tuning on legal documents  
- **Function**: Generates abstractive summaries that capture key information from lengthy documents  
- **Advantage**: Produces readable summaries that maintain legal accuracy and relevance  

---

## ğŸ“¥ Data Collection

The system uses legal cases from the **U.S. Court of International Trade (CIT)** between 2023 and 2025. Data was collected using the following process:

- ğŸ” **Web scraping** from [law.justia.com](https://law.justia.com) using Selenium  
  *(See `0_web_scraping_cases.ipynb`)*

- ğŸ“„ **Converting PDF documents to text**  
  *(See `1_convert_cases_pdf_to_txt.ipynb`)*

- ğŸ§  **Processing and embedding texts for efficient retrieval**  
  *(See `case_embeddings_to_pickle.ipynb`)*
